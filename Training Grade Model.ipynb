{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Training Grade model given text</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade given text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nltk.download' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "* Reading training data \n",
    "\n",
    "I read 10 datasets from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records read :  472120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learnerId</th>\n",
       "      <th>nationality</th>\n",
       "      <th>grade</th>\n",
       "      <th>level</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>grade_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84805</td>\n",
       "      <td>mx</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>Summarizing a story</td>\n",
       "      <td>make is a live''s jeans an shit favorit...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139062</td>\n",
       "      <td>cn</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>Complaining about a meal</td>\n",
       "      <td>19th June 2012I went to a restaurant an...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162010</td>\n",
       "      <td>tw</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>Writing a movie plot</td>\n",
       "      <td>Although Isabella had married, but his ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60036</td>\n",
       "      <td>ru</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>Taking inventory in the office</td>\n",
       "      <td>The code of conduct: - do not disclose ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88813</td>\n",
       "      <td>mx</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>Describing a business trip</td>\n",
       "      <td>I have fantastic news. Finally I met wi...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learnerId nationality  grade  level                           topic  \\\n",
       "0      84805          mx     90      5             Summarizing a story   \n",
       "1     139062          cn     90      6        Complaining about a meal   \n",
       "2     162010          tw     83      6            Writing a movie plot   \n",
       "3      60036          ru     94      1  Taking inventory in the office   \n",
       "4      88813          mx    100      8      Describing a business trip   \n",
       "\n",
       "                                                text grade_bucket  \n",
       "0         make is a live''s jeans an shit favorit...            9  \n",
       "1         19th June 2012I went to a restaurant an...            9  \n",
       "2         Although Isabella had married, but his ...            9  \n",
       "3         The code of conduct: - do not disclose ...           10  \n",
       "4         I have fantastic news. Finally I met wi...           10  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfDatasets = 10\n",
    "def readData(numberOfDatasets, counter):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(counter, counter+numberOfDatasets):\n",
    "        tempDf = pd.read_csv(\"./Part\"+str(i+1)+\".csv\")\n",
    "        df = df.append(tempDf)\n",
    "    return df\n",
    "\n",
    "train = readData(numberOfDatasets,0)\n",
    "train['grade_bucket'] = train['grade'].apply(lambda x: 1 if x<=10 else (2 if (x>10 and x<=20) else (3 if (x>20 and x<=30) else (4 if (x>30 and x<=40) else (5 if (x>40 and x<=50) else (6 if(x>50 and x<=60) else(7 if(x>60 and x<=70) else (8 if (x>70 and x<=80) else (9 if (x>80 and x<=90) else (10) )   )  )  )  )  )    )   ) )\n",
    "train['grade_bucket'] = train['grade_bucket'].astype('category')\n",
    "print (\"Total number of records read : \", len(train))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records read :  94424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learnerId</th>\n",
       "      <th>nationality</th>\n",
       "      <th>grade</th>\n",
       "      <th>level</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>grade_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34458</td>\n",
       "      <td>br</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>Writing a job advertisement</td>\n",
       "      <td>Open possition for Finance Administrati...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136384</td>\n",
       "      <td>mx</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>Writing about what you like doing</td>\n",
       "      <td>Hello Dillo. how are you?thank you for ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135078</td>\n",
       "      <td>it</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>Replying to a new penpal</td>\n",
       "      <td>Hi, my names NATASCIA. Im twenty-eight....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21417</td>\n",
       "      <td>ru</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>Describing a friend's weekend routine</td>\n",
       "      <td>On Saturday, he goes swimming at 11:30a...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170106</td>\n",
       "      <td>br</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>Writing labels for a clothing store</td>\n",
       "      <td>This black skirt is 15,00. These red an...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learnerId nationality  grade  level                                  topic  \\\n",
       "0      34458          br     90      7            Writing a job advertisement   \n",
       "1     136384          mx     79      4      Writing about what you like doing   \n",
       "2     135078          it     95      3               Replying to a new penpal   \n",
       "3      21417          ru    100      3  Describing a friend's weekend routine   \n",
       "4     170106          br     95      1    Writing labels for a clothing store   \n",
       "\n",
       "                                                text grade_bucket  \n",
       "0         Open possition for Finance Administrati...            9  \n",
       "1         Hello Dillo. how are you?thank you for ...            8  \n",
       "2         Hi, my names NATASCIA. Im twenty-eight....           10  \n",
       "3         On Saturday, he goes swimming at 11:30a...           10  \n",
       "4         This black skirt is 15,00. These red an...           10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = readData(2, 10)\n",
    "test['grade_bucket'] = test['grade'].apply(lambda x: 1 if x<=10 else (2 if (x>10 and x<=20) else (3 if (x>20 and x<=30) else (4 if (x>30 and x<=40) else (5 if (x>40 and x<=50) else (6 if(x>50 and x<=60) else(7 if(x>60 and x<=70) else (8 if (x>70 and x<=80) else (9 if (x>80 and x<=90) else (10) )   )  )  )  )  )    )   ) )\n",
    "test['grade_bucket'] = test['grade_bucket'].astype('category')\n",
    "print (\"No. of records read : \", len(test))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "Doing pre-processing of text data:\n",
    "\n",
    "* lowercase of text\n",
    "* remove of all puncuation and keeping onl alphanumeric characters\n",
    "* tokenizing using nltk and re-merging for removal of bad spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=train['text'].apply(lambda x : \" \".join(nltk.tokenize.word_tokenize(re.sub(r'\\W+', \" \", x.lower()))))\n",
    "\n",
    "test['text']=test['text'].apply(lambda x : \" \".join(nltk.tokenize.word_tokenize(re.sub(r'\\W+', \" \", x.lower()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building X_train, Y_train, X_test and Y_test for Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'make is a live s jeans an shit favorit make is the ralp laurens polo is somewhat expensive but i think worth the money mifavorit foot wear is the sport shoe is nike make i think are is berygood quality and comfortables',\n",
       "       '19th june 2012i went to a restaurant and i had a terrible meal the starter soup was bland the dessert was too sweet the horrible is red wine and coffee was disgusting bitter also the steak was overcooked and there was chilli powder with it it was very unhappy meal sharon',\n",
       "       'although isabella had married but his husband is very awful and violent so she want to divorce early they were talking very happy after that they are talking on the ship every night day after day john and isabella fall in love and they decide to have an elopement finally they were hold a wedding in other a country and had three children after three years the story have a happy ending',\n",
       "       'the code of conduct do not disclose confidential information keep your workspace neat and tidy do not disturb colleaues with loud music arrive to work on time abide by the dress code use the smoking area do not discriminate against other staff members',\n",
       "       'i have fantastic news finally i met with sally cassidy although our meeting was a little bit informal because we ate at steakhouse it was very productive we reviewed the past year and hear this she told me that gxc wants to increase purchases from us by 20 can you believe it after she gave the great news i have been thinking that our relationship is growing as is our business with this maybe we can growth this year as we had planned one more thing sally told me she wants to meet us again to talk about future projects and how we can help gxc to accomplish them'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = train['text'].values, train['grade_bucket'].values\n",
    "X_test, Y_test = test['text'].values, test['grade_bucket'].values\n",
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Converting Y to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1   2   3   4   5   6   7   8   9   10\n",
       "0   0   0   0   0   0   0   0   0   1   0\n",
       "1   0   0   0   0   0   0   0   0   1   0\n",
       "2   0   0   0   0   0   0   0   0   1   0\n",
       "3   0   0   0   0   0   0   0   0   0   1\n",
       "4   0   0   0   0   0   0   0   0   0   1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_OneHot_Train = pd.get_dummies(Y_train)\n",
    "Y_OneHot_Test = pd.get_dummies(Y_test)\n",
    "classes = len(Y_OneHot_Train.columns.values)\n",
    "Y_OneHot_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_OneHot_Train = Y_OneHot_Train.values\n",
    "Y_OneHot_Test = Y_OneHot_Test.values\n",
    "Y_OneHot_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGlove(filename):   \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map, words\n",
    "\n",
    "gloveVecFile = \"./glove.6B.50d.txt\"\n",
    "words_to_index, index_to_words, word_to_vec_map, words = readGlove(gloveVecFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting sentences to indices vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()`\n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. One can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape\n",
    "    X_indices = np.zeros(shape=(m, max_len))\n",
    "    \n",
    "    for i in range(m):                               \n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "        sentence_words =X[i].lower().strip().split()\n",
    "        \n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            try:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            except KeyError as e:\n",
    "                X_indices[i, j] = word_to_index[\"unk\"]\n",
    "            # Increment j to j + 1\n",
    "            j = j + 1\n",
    "            if j>=max_len:\n",
    "                break\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining pre-training embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      \n",
    "    \n",
    "    emb_matrix = np.zeros(shape=(vocab_len, emb_dim))\n",
    "    \n",
    "    for word, index in word_to_index.items():\n",
    "        try:\n",
    "            emb_matrix[index, :] = word_to_vec_map[word]\n",
    "        except Exception as e:\n",
    "            print (\"Exception {0} occured for word {1}\".format(e, word))\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nation(input_shape, word_to_vec_map, word_to_index):    \n",
    "    sentence_indices = Input(shape=input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    X = LSTM(264)(embeddings)\n",
    "#     X = LSTM(264)(embeddings)\n",
    "   \n",
    "    # Add dropout with a probability of 0.5 to prevent overfitting\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "#     X = LSTM(264)(X)\n",
    "    \n",
    "#     # Add dropout with a probability of 0.5\n",
    "#     X = Dropout(rate = 0.5)(X)\n",
    "\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 191-dimensional vectors.\n",
    "    X = Dense(classes, activation='relu')(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 200, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 264)               332640    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 264)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2650      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 20,335,340\n",
      "Trainable params: 335,290\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxLen = 200 # Determined from the EDA notebook\n",
    "model = nation((maxLen,), word_to_vec_map, words_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, words_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 377696 samples, validate on 94424 samples\n",
      "Epoch 1/1\n",
      "377696/377696 [==============================] - 11696s 31ms/step - loss: 1.2343 - acc: 0.4481 - val_loss: 1.2196 - val_acc: 0.4571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x8aab2edf60>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_OneHot_Train, epochs = 1, batch_size = 50, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"./GradeVsText.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "* Below are some of the metrics on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, words_to_index, max_len = maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94424/94424 [==============================] - 834s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test_indices, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred\n",
    "Y_test_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "Y_test_map = {}\n",
    "for index, country in enumerate(Y_train.categories.values):\n",
    "    Y_test_map[country] = index\n",
    "    \n",
    "def getYTestActual(Y_test_map, Y_test):\n",
    "    Y_test_actual= []\n",
    "    for value in Y_test:\n",
    "        Y_test_actual.append(Y_test_map.get(value))\n",
    "    return Y_test_actual\n",
    "\n",
    "Y_test_actual = getYTestActual(Y_test_map, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy : 45.52020672710328%\n"
     ]
    }
   ],
   "source": [
    "print (\"Testing set accuracy : {0}%\".format(100*np.mean(np.equal(Y_test_actual, Y_test_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on any validation data set\n",
    "\n",
    "* I have created 25 files of approx. 18MB size each. 1-10 are used for training and 11-12 are used for validation\n",
    "* Provide any File Part number (except 1 - 12, 1-10 is used for training and 11-12 are already used for validation) from 13-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide any part number for validation\n",
    "part_no = 22 # user choice\n",
    "validation_df = pd.read_csv(\"./Desktop/NLP_New/source/Part\"+str(part_no)+\".csv\")\n",
    "X_validation_indices = sentences_to_indices(validation_df['text'].values, words_to_index, max_len = maxLen)\n",
    "Y_validation_actual = getYTestActual(Y_test_map, validation_df['level'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from disk ...\n",
      "model loaded\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 200, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 264)               332640    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 264)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2650      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 20,335,340\n",
      "Trainable params: 335,290\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n",
      "None\n",
      "47212/47212 [==============================] - 409s 9ms/step\n",
      "Validation set accuracy : 3.094552232483267%\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading model from disk ...\")\n",
    "model = load_model(\"./GradeVsText.hdf5\")\n",
    "print (\"model loaded\")\n",
    "print (model.summary())\n",
    "pred = model.predict(X_validation_indices, verbose=1) \n",
    "Y_validation_pred = np.argmax(pred, axis=1)\n",
    "print (\"Validation set accuracy : {0}%\".format(100*np.mean(np.equal(Y_validation_actual, Y_validation_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
