{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Predicting Nationality given text</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from matplotlib_venn import venn2\n",
    "import re\n",
    "import nltk\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "I read 10 datasets from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records read :  472120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learnerId</th>\n",
       "      <th>nationality</th>\n",
       "      <th>grade</th>\n",
       "      <th>level</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84805</td>\n",
       "      <td>mx</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>Summarizing a story</td>\n",
       "      <td>make is a live''s jeans an shit favorit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139062</td>\n",
       "      <td>cn</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>Complaining about a meal</td>\n",
       "      <td>19th June 2012I went to a restaurant an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162010</td>\n",
       "      <td>tw</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>Writing a movie plot</td>\n",
       "      <td>Although Isabella had married, but his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60036</td>\n",
       "      <td>ru</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>Taking inventory in the office</td>\n",
       "      <td>The code of conduct: - do not disclose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88813</td>\n",
       "      <td>mx</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>Describing a business trip</td>\n",
       "      <td>I have fantastic news. Finally I met wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learnerId nationality  grade  level                           topic  \\\n",
       "0      84805          mx     90      5             Summarizing a story   \n",
       "1     139062          cn     90      6        Complaining about a meal   \n",
       "2     162010          tw     83      6            Writing a movie plot   \n",
       "3      60036          ru     94      1  Taking inventory in the office   \n",
       "4      88813          mx    100      8      Describing a business trip   \n",
       "\n",
       "                                                text  \n",
       "0         make is a live''s jeans an shit favorit...  \n",
       "1         19th June 2012I went to a restaurant an...  \n",
       "2         Although Isabella had married, but his ...  \n",
       "3         The code of conduct: - do not disclose ...  \n",
       "4         I have fantastic news. Finally I met wi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfDatasets = 10\n",
    "def readData(numberOfDatasets, counter):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(counter, counter+numberOfDatasets):\n",
    "        tempDf = pd.read_csv(\"./Part\"+str(i+1)+\".csv\")\n",
    "        df = df.append(tempDf)\n",
    "    return df\n",
    "\n",
    "train = readData(numberOfDatasets,0)\n",
    "train['nationality'] = train['nationality'].astype('category')\n",
    "print (\"Total number of records read : \", len(train))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of records read :  94424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learnerId</th>\n",
       "      <th>nationality</th>\n",
       "      <th>grade</th>\n",
       "      <th>level</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34458</td>\n",
       "      <td>br</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>Writing a job advertisement</td>\n",
       "      <td>Open possition for Finance Administrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136384</td>\n",
       "      <td>mx</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>Writing about what you like doing</td>\n",
       "      <td>Hello Dillo. how are you?thank you for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135078</td>\n",
       "      <td>it</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>Replying to a new penpal</td>\n",
       "      <td>Hi, my names NATASCIA. Im twenty-eight....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21417</td>\n",
       "      <td>ru</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>Describing a friend's weekend routine</td>\n",
       "      <td>On Saturday, he goes swimming at 11:30a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170106</td>\n",
       "      <td>br</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>Writing labels for a clothing store</td>\n",
       "      <td>This black skirt is 15,00. These red an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learnerId nationality  grade  level                                  topic  \\\n",
       "0      34458          br     90      7            Writing a job advertisement   \n",
       "1     136384          mx     79      4      Writing about what you like doing   \n",
       "2     135078          it     95      3               Replying to a new penpal   \n",
       "3      21417          ru    100      3  Describing a friend's weekend routine   \n",
       "4     170106          br     95      1    Writing labels for a clothing store   \n",
       "\n",
       "                                                text  \n",
       "0         Open possition for Finance Administrati...  \n",
       "1         Hello Dillo. how are you?thank you for ...  \n",
       "2         Hi, my names NATASCIA. Im twenty-eight....  \n",
       "3         On Saturday, he goes swimming at 11:30a...  \n",
       "4         This black skirt is 15,00. These red an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = readData(2, 10)\n",
    "test['nationality'] = test['nationality'].astype('category')\n",
    "print (\"No. of records read : \", len(test))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "Doing pre-processing of text data:\n",
    "\n",
    "* lowercase of text\n",
    "* remove of all puncuation and keeping onl alphanumeric characters\n",
    "* tokenizing using nltk and re-merging for removal of bad spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['text']=train['text'].apply(lambda x : \" \".join(nltk.tokenize.word_tokenize(re.sub(r'\\W+', \" \", x.lower()))))\n",
    "\n",
    "test['text']=test['text'].apply(lambda x : \" \".join(nltk.tokenize.word_tokenize(re.sub(r'\\W+', \" \", x.lower()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building X_train, Y_train, X_test and Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['make is a live s jeans an shit favorit make is the ralp laurens polo is somewhat expensive but i think worth the money mifavorit foot wear is the sport shoe is nike make i think are is berygood quality and comfortables',\n",
       "       '19th june 2012i went to a restaurant and i had a terrible meal the starter soup was bland the dessert was too sweet the horrible is red wine and coffee was disgusting bitter also the steak was overcooked and there was chilli powder with it it was very unhappy meal sharon',\n",
       "       'although isabella had married but his husband is very awful and violent so she want to divorce early they were talking very happy after that they are talking on the ship every night day after day john and isabella fall in love and they decide to have an elopement finally they were hold a wedding in other a country and had three children after three years the story have a happy ending',\n",
       "       'the code of conduct do not disclose confidential information keep your workspace neat and tidy do not disturb colleaues with loud music arrive to work on time abide by the dress code use the smoking area do not discriminate against other staff members',\n",
       "       'i have fantastic news finally i met with sally cassidy although our meeting was a little bit informal because we ate at steakhouse it was very productive we reviewed the past year and hear this she told me that gxc wants to increase purchases from us by 20 can you believe it after she gave the great news i have been thinking that our relationship is growing as is our business with this maybe we can growth this year as we had planned one more thing sally told me she wants to meet us again to talk about future projects and how we can help gxc to accomplish them'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k fold only\n",
    "train = train.head(45000)\n",
    "\n",
    "X_train, Y_train = train['text'].values, train['nationality'].values\n",
    "X_test, Y_test = test['text'].values, test['nationality'].values\n",
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Y to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad</th>\n",
       "      <th>ae</th>\n",
       "      <th>af</th>\n",
       "      <th>ai</th>\n",
       "      <th>al</th>\n",
       "      <th>am</th>\n",
       "      <th>ao</th>\n",
       "      <th>aq</th>\n",
       "      <th>ar</th>\n",
       "      <th>as</th>\n",
       "      <th>...</th>\n",
       "      <th>uy</th>\n",
       "      <th>uz</th>\n",
       "      <th>vc</th>\n",
       "      <th>ve</th>\n",
       "      <th>vg</th>\n",
       "      <th>vn</th>\n",
       "      <th>vu</th>\n",
       "      <th>ye</th>\n",
       "      <th>za</th>\n",
       "      <th>zw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad  ae  af  ai  al  am  ao  aq  ar  as ...  uy  uz  vc  ve  vg  vn  vu  ye  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "2   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "3   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "4   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   za  zw  \n",
       "0   0   0  \n",
       "1   0   0  \n",
       "2   0   0  \n",
       "3   0   0  \n",
       "4   0   0  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_OneHot_Train = pd.get_dummies(Y_train)\n",
    "Y_OneHot_Test = pd.get_dummies(Y_test)\n",
    "classes = len(Y_OneHot_Train.columns.values)\n",
    "Y_OneHot_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_OneHot_Train = Y_OneHot_Train.values\n",
    "Y_OneHot_Test = Y_OneHot_Test.values\n",
    "Y_OneHot_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading GloVe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readGlove(filename):   \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map, words\n",
    "\n",
    "gloveVecFile = \"./glove.6B.50d.txt\"\n",
    "words_to_index, index_to_words, word_to_vec_map, words = readGlove(gloveVecFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intersection of words in dataset with words in GloVe vector\n",
    "\n",
    "def getSetOfWords(text) :\n",
    "    \"\"\"\n",
    "    :param : text is an numpy array of strings\n",
    "    \"\"\"\n",
    "    setOfWordsInTrainingDataset = set()\n",
    "    for sentence in text:\n",
    "        for word in sentence.split():\n",
    "            setOfWordsInTrainingDataset.add(word)\n",
    "    return setOfWordsInTrainingDataset\n",
    "\n",
    "setOfWordsInTrainingDataset = getSetOfWords(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAFuCAYAAAC1G64rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkYL4/xcIXVm+pDoZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "venn2([words, setOfWordsInTrainingDataset],set_labels = ('GloVe vector', 'Dataset'))\n",
    "plt.show()\n",
    "# type(setOfWordsInTrainingDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6558743395339526% words are not found in GloVe vector\n"
     ]
    }
   ],
   "source": [
    "print (str(150695/(150695+79067))+\"% words are not found in GloVe vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting sentences to indices vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()`\n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. One can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape\n",
    "    X_indices = np.zeros(shape=(m, max_len))\n",
    "    \n",
    "    for i in range(m):                               \n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "        sentence_words =X[i].lower().strip().split()\n",
    "        \n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            try:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            except KeyError as e:\n",
    "                X_indices[i, j] = word_to_index[\"unk\"]\n",
    "            # Increment j to j + 1\n",
    "            j = j + 1\n",
    "            if j>=max_len:\n",
    "                break\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining pre-training embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      \n",
    "    \n",
    "    emb_matrix = np.zeros(shape=(vocab_len, emb_dim))\n",
    "    \n",
    "    for word, index in word_to_index.items():\n",
    "        try:\n",
    "            emb_matrix[index, :] = word_to_vec_map[word]\n",
    "        except Exception as e:\n",
    "            print (\"Exception {0} occured for word {1}\".format(e, word))\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nation(input_shape, word_to_vec_map, word_to_index):    \n",
    "    sentence_indices = Input(shape=input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    X = LSTM(264)(embeddings)\n",
    "#     X = LSTM(264)(embeddings)\n",
    "   \n",
    "    # Add dropout with a probability of 0.5 to prevent overfitting\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "#     X = LSTM(264)(X)\n",
    "    \n",
    "#     # Add dropout with a probability of 0.5\n",
    "#     X = Dropout(rate = 0.5)(X)\n",
    "\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 191-dimensional vectors.\n",
    "    X = Dense(classes, activation='relu')(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(sentence_indices, X)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saurabh/miniconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1044: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 264)               332640    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 264)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 191)               50615     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 191)               0         \n",
      "=================================================================\n",
      "Total params: 20,383,305.0\n",
      "Trainable params: 383,255.0\n",
      "Non-trainable params: 20,000,050.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxLen = 200 # Determined from the EDA notebook\n",
    "model = nation((maxLen,), word_to_vec_map, words_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saurabh/miniconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1123: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "## Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, words_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 377696 samples, validate on 94424 samples\n",
      "Epoch 1/1\n",
      "377696/377696 [==============================] - 8040s - loss: 2.4297 - acc: 0.4028 - val_loss: 2.2747 - val_acc: 0.4159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4d8e6f630>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_OneHot_Train, epochs = 1, batch_size = 50, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"./NationalityVsText_v2.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model using K-fold cross validation\n",
    "\n",
    "* Below code is commented. \n",
    "* Uncomment and run the below cell to train the model using 10-fold cross validation\n",
    "* I did not do this, because it was taking too much time - 2 hrs for 1 epoch on 1 validation data\n",
    "* Feel free to change number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh/miniconda3/lib/python3.5/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "35982/35982 [==============================] - 742s - loss: 2.5593 - acc: 0.3925   \n",
      "Epoch 2/2\n",
      "35982/35982 [==============================] - 702s - loss: 2.4763 - acc: 0.3996   \n",
      "<keras.callbacks.History object at 0x7fd82b1212b0>\n",
      "9018/9018 [==============================] - 57s    \n",
      "acc: 39.88%\n",
      "Epoch 1/2\n",
      "35983/35983 [==============================] - 771s - loss: 2.6136 - acc: 0.3944   \n",
      "Epoch 2/2\n",
      "35983/35983 [==============================] - 706s - loss: 2.5287 - acc: 0.3996   \n",
      "<keras.callbacks.History object at 0x7fd812a64828>\n",
      "9017/9017 [==============================] - 57s    \n",
      "acc: 39.88%\n",
      "Epoch 1/2\n",
      "35988/35988 [==============================] - 690s - loss: 2.5914 - acc: 0.3930   \n",
      "Epoch 2/2\n",
      "35988/35988 [==============================] - 692s - loss: 2.4757 - acc: 0.3995   \n",
      "<keras.callbacks.History object at 0x7fd812fe3ac8>\n",
      "9012/9012 [==============================] - 57s    \n",
      "acc: 39.89%\n",
      "Epoch 1/2\n",
      "35996/35996 [==============================] - 960s - loss: 2.5645 - acc: 0.3924   \n",
      "Epoch 2/2\n",
      "35996/35996 [==============================] - 764s - loss: 2.4602 - acc: 0.3995   \n",
      "<keras.callbacks.History object at 0x7fd8130ff1d0>\n",
      "9004/9004 [==============================] - 57s    \n",
      "acc: 39.93%\n",
      "Epoch 1/2\n",
      "36051/36051 [==============================] - 690s - loss: 2.6554 - acc: 0.3929   \n",
      "Epoch 2/2\n",
      "36051/36051 [==============================] - 798s - loss: 2.5711 - acc: 0.3989   \n",
      "<keras.callbacks.History object at 0x7fd8040637f0>\n",
      "8949/8949 [==============================] - 67s    \n",
      "acc: 40.17%\n",
      "Final k-fold result : 39.95% (+/- 0.11%)\n"
     ]
    }
   ],
   "source": [
    "seed = 8\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X_train, Y_train):\n",
    "    # Fit the model\n",
    "    X_train_indices = sentences_to_indices(X_train[train], words_to_index, maxLen)\n",
    "    Y_OneHot_Train = pd.get_dummies(Y_train[train]).values\n",
    "    \n",
    "    model = nation((maxLen,), word_to_vec_map, words_to_index)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print (model.fit(X_train_indices, Y_OneHot_Train, epochs=2, batch_size=50, verbose=1))\n",
    "    \n",
    "    # evaluate the model\n",
    "    X_test_indices = sentences_to_indices(X_train[test], words_to_index, maxLen)\n",
    "    pred = model.predict(X_test_indices, verbose=1)\n",
    "    Y_test_pred = np.argmax(pred, axis=1)\n",
    "    Y_test_map = {}\n",
    "    for index, country in enumerate(Y_train[train].categories.values):\n",
    "        Y_test_map[country] = index\n",
    "    Y_test_actual= []\n",
    "    for value in Y_train[test]:\n",
    "        Y_test_actual.append(Y_test_map.get(value))\n",
    "        \n",
    "    scores= np.mean(np.equal(Y_test_actual, Y_test_pred))\n",
    "    print(\"acc: %.2f%%\" % (100*scores))\n",
    "    cvscores.append(scores * 100)\n",
    "print(\"Final k-fold result : %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "Below are some of the metrics on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, words_to_index, max_len = maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94424/94424 [==============================] - 667s   \n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test_indices, verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred\n",
    "Y_test_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "Y_test_map = {}\n",
    "for index, country in enumerate(Y_train.categories.values):\n",
    "    Y_test_map[country] = index\n",
    "    \n",
    "def getYTestActual(Y_test_map, Y_test):\n",
    "    Y_test_actual= []\n",
    "    for value in Y_test:\n",
    "        Y_test_actual.append(Y_test_map.get(value))\n",
    "    return Y_test_actual\n",
    "\n",
    "Y_test_actual = getYTestActual(Y_test_map, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print (\"Below is the confusion matrix for model1: \")\n",
    "# confusion_matrix(Y_test_actual, Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy : 40.34249767008388%\n"
     ]
    }
   ],
   "source": [
    "len(Y_test_actual), len(Y_test_pred)\n",
    "print (\"Testing set accuracy : {0}%\".format(100*np.mean(np.equal(Y_test_actual, Y_test_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on any validation data set\n",
    "\n",
    "* I have created 25 files of approx. 18MB size each. 1-10 are used for training and 11-12 are used for validation\n",
    "* Provide any File Part number (except 1 - 12, 1-10 is used for training and 11-12 are already used for validation) from 13-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Provide any part number for validation\n",
    "part_no = 22 # user choice\n",
    "validation_df = pd.read_csv(\"./Part\"+str(part_no)+\".csv\")\n",
    "X_validation_indices = sentences_to_indices(validation_df['text'].values, words_to_index, max_len = maxLen)\n",
    "Y_validation_actual = getYTestActual(Y_test_map, validation_df['nationality'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from disk ...\n",
      "model loaded\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 200, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 264)               332640    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 264)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 191)               50615     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 191)               0         \n",
      "=================================================================\n",
      "Total params: 20,383,305.0\n",
      "Trainable params: 383,255.0\n",
      "Non-trainable params: 20,000,050.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "47212/47212 [==============================] - 324s   \n",
      "Validation set accuracy : 40.07243921037025%\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading model from disk ...\")\n",
    "model = load_model(\"./NationalityVsText_v2.hdf5\")\n",
    "print (\"model loaded\")\n",
    "print (model.summary())\n",
    "pred = model.predict(X_validation_indices, verbose=1) \n",
    "Y_validation_pred = np.argmax(pred, axis=1)\n",
    "print (\"Validation set accuracy : {0}%\".format(100*np.mean(np.equal(Y_validation_actual, Y_validation_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
